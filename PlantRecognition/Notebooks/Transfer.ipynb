{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1UndLGU97Vp_jZR0bR1LHjR62y0lhBUtl","authorship_tag":"ABX9TyMAO18e0DtJ0cU85FqWT/hI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Transfer auf Embedded System"],"metadata":{"id":"xKod_-AmlJbA"}},{"cell_type":"code","source":["!pip install --upgrade tensorflow\n","!pip install --upgrade keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPsKW1Fq_hpE","executionInfo":{"status":"ok","timestamp":1723061684215,"user_tz":-120,"elapsed":27121,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"e8429986-1380-4be7-c052-7a039293b09f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"]}]},{"cell_type":"markdown","source":["# Kuzer Zwischentest\n","Test der Funktion des nicht quantisierten Modells"],"metadata":{"id":"VpYmYs9ubyJA"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import numpy as np"],"metadata":{"id":"E5ga-73nb3If"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model('/content/drive/MyDrive/Colab Notebooks/models/modelMitFein_07_08_2024.keras')"],"metadata":{"id":"3elC81TOb_fx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def to_grayscale_with_channels(img_array):\n","    # Bild in Grayscale konvertieren\n","    grayscale_image = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])\n","    # Erzeuge ein 3-Kanal-Grayscale-Bild\n","    grayscale_image_3_channels = np.stack((grayscale_image,)*3, axis=-1)\n","    return grayscale_image_3_channels\n","\n","def load_and_preprocess_image(img_path):\n","    # Lade das Bild und ändere die Größe\n","    img = image.load_img(img_path, target_size=(200, 200))\n","    # Wandle das Bild in ein Array um\n","    img_array = image.img_to_array(img)\n","    # Konvertiere das Bild zu Graustufen mit drei Kanälen\n","    img_array = to_grayscale_with_channels(img_array)\n","    # Erweitere die Dimensionen, um eine Batch-Dimension hinzuzufügen\n","    img_array = np.expand_dims(img_array, axis=0)\n","    # Normalisiere die Pixelwerte (optional, abhängig von der VGG16-Implementierung)\n","    img_array /= 255.0\n","    return img_array\n"],"metadata":{"id":"787f7vJ7cpIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(model, img_path, threshold=0.5):\n","    # Bild laden und vorverarbeiten\n","    img_array = load_and_preprocess_image(img_path)\n","    # Vorhersage durchführen\n","    prediction = model.predict(img_array)\n","    # Wahrscheinlichkeitswert\n","    probability = prediction[0][0]\n","    # Klassenzuordnung basierend auf dem Schwellenwert\n","    predicted_class = 1 if probability >= threshold else 0\n","    return probability, predicted_class\n","\n","img_path = '/content/drive/MyDrive/Colab Notebooks/Set_12_05_24/test/Basilikum/159.jpg'\n","probability, predicted_class = predict_image(model, img_path)\n","\n","print(f'Wahrscheinlichkeit für die positive Klasse: {probability}')\n","print(f'Vorhergesagte Klasse: {predicted_class}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UivzKv6KcwYN","executionInfo":{"status":"ok","timestamp":1723061418949,"user_tz":-120,"elapsed":1647,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"34a3baf5-8295-4bf2-ab6e-734ae292755a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898ms/step\n","Wahrscheinlichkeit für die positive Klasse: 3.812175418715924e-05\n","Vorhergesagte Klasse: 0\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras"],"metadata":{"id":"CmpBNqKDC6GX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Tensorflow Version:\", tf.__version__)\n","print(\"Keras Version:\", keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sn9-qD1hC-nu","executionInfo":{"status":"ok","timestamp":1723061714219,"user_tz":-120,"elapsed":322,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"383ba727-07c4-4328-f02b-d68104f10ae5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow Version: 2.17.0\n","Keras Version: 3.4.1\n"]}]},{"cell_type":"markdown","source":["# Neuer versuch Konvertierung ohne Quantisierung"],"metadata":{"id":"McifYsmmRJXP"}},{"cell_type":"code","source":["model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/models/modelMitFein_07_08_2024.keras\")"],"metadata":{"id":"mtNtG7-zI8Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","new_tf_lite = converter.convert()"],"metadata":{"id":"N9w7MyFBI8BK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723055836932,"user_tz":-120,"elapsed":8215,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"5d4275fb-14eb-41cd-8c2a-d314eb7b6e4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmp6_spbo8y'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer_1')\n","Output Type:\n","  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n","Captures:\n","  136314482113904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398593040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398600608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398604304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398643248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398646944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398647472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398650992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398647648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398654160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398653280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398653632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398720240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398724816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398726048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398728336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398722704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398730800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398726224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398733264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398734496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398733968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398735904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314482113376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314482111616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314482103872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398595680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398837392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398835104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  136314398840032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]}]},{"cell_type":"code","source":["new_tflite_model_path = '/content/drive/MyDrive/Colab Notebooks/models/newLiteModel_07_08_2024.tflite'\n","\n","# TensorFlow Lite Modell in eine Datei speichern\n","with open(new_tflite_model_path, 'wb') as f:\n","    f.write(new_tf_lite)"],"metadata":{"id":"Kbs2eL5XgOGb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Älterer Versuch mit Quantisierung"],"metadata":{"id":"TJAf152_S8kh"}},{"cell_type":"code","source":["# Konvertierung des trainierten Modells in ein Tensorflow Lite Modell\n","converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/drive/MyDrive/Colab Notebooks/models/export\")\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]"],"metadata":{"id":"WnPRBys_lPc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Quantisierungseinstellungen\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.uint8\n","converter.inference_output_type = tf.uint8"],"metadata":{"id":"sUPm1XVSpqVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","\n","# Funktion zur Erweiterung des Graustufenbildes auf drei Kanäle\n","def to_grayscale_with_channels(image):\n","    # Bild in Grayscale konvertieren\n","    grayscale_image = np.dot(image[...,:3], [0.2989, 0.5870, 0.1140])\n","\n","    # Erzeuge ein 3-Kanal-Grayscale-Bild\n","    grayscale_image_3_channels = np.stack((grayscale_image,)*3, axis=-1)\n","\n","    return grayscale_image_3_channels\n","\n","test_dir = \"/content/drive/MyDrive/Colab Notebooks/Set_12_05_24/test\"\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    preprocessing_function=to_grayscale_with_channels,\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(200, 200),\n","    batch_size=89,\n","    class_mode=\"binary\",\n","    color_mode=\"rgb\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iczQ15Nc0_DM","executionInfo":{"status":"ok","timestamp":1723061810144,"user_tz":-120,"elapsed":328,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"c5984451-8611-4164-ca50-24226873dba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 89 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["# tensorflow lite benötigt ein representatives Dataset, um die Quantisierung durchführen zu können\n","# es werden hierfür die Testdaten verwendet\n","def representative_dataset():\n","  for _ in range(len(test_generator)):\n","    batch = next(test_generator)[0]\n","    yield [batch]"],"metadata":{"id":"VvNbzmqet-Nq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setze das repräsentative Datenset für die Quantisierung\n","converter.representative_dataset = representative_dataset"],"metadata":{"id":"FxAxXxrnv4nr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Konvertierung ausführen\n","tflite_model = converter.convert()"],"metadata":{"id":"5NuVVtz4ps_x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719091847498,"user_tz":-120,"elapsed":98974,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"81e83fcd-9076-4139-d3b2-317ea834fac9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["tflite_model_path = '/content/drive/MyDrive/Colab Notebooks/models/liteModel.tflite'\n","\n","# TensorFlow Lite Modell in eine Datei speichern\n","with open(tflite_model_path, 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"NJX3E9rA2NJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","\n","# Laden des TensorFlow Lite Modells\n","interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Colab Notebooks/models/liteModel.tflite\")\n","interpreter.allocate_tensors()"],"metadata":{"id":"h5sO0RBD3buW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Details des Eingabentensors\n","input_details = interpreter.get_input_details()\n","print(\"Eingabetensor Details:\", input_details)\n","\n","# Details des Ausgabetensors\n","output_details = interpreter.get_output_details()\n","print(\"Ausgabetensor Details:\", output_details)\n","\n","# Größe des Modells\n","model_size = os.path.getsize(\"/content/drive/MyDrive/Colab Notebooks/models/liteModel.tflite\")\n","print(\"Modellgröße:\", model_size, \"Bytes\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZg5TeYb5vw4","executionInfo":{"status":"ok","timestamp":1719092636084,"user_tz":-120,"elapsed":253,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"dfeedf6f-6e1e-40c2-c8b9-887ef61ee2b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Eingabetensor Details: [{'name': 'serving_default_input_layer_1:0', 'index': 0, 'shape': array([  1, 200, 200,   3], dtype=int32), 'shape_signature': array([ -1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003921176306903362, 0), 'quantization_parameters': {'scales': array([0.00392118], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","Ausgabetensor Details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 55, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.00390625, 0), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","Modellgröße: 19559528 Bytes\n"]}]},{"cell_type":"markdown","source":["# Test des TF-Lite Modells"],"metadata":{"id":"TsqfYaEw_3qT"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"bBMcaBqs516Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Tensorflow Version:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7MGEOGKDJX9","executionInfo":{"status":"ok","timestamp":1722769268803,"user_tz":-120,"elapsed":484,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"411c4dc6-f5e1-4278-c8dd-7da73708c6ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow Version: 2.17.0\n"]}]},{"cell_type":"markdown","source":["## TF-Lite Modell laden"],"metadata":{"id":"hw1QgZLtDbMJ"}},{"cell_type":"code","source":["interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Colab Notebooks/models/newLiteModel_07_08_2024.tflite\")"],"metadata":{"id":"FEQ7VIYwDVAe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Eingabe und Ausgabe Details des Modells abrufen"],"metadata":{"id":"cSEJiZf1EZzM"}},{"cell_type":"code","source":["input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","print(\"Input Shape:\", input_details[0]['shape'])\n","print(\"Input Type:\", input_details[0]['dtype'])\n","print(\"Output Shape:\", output_details[0]['shape'])\n","print(\"Output Type:\", output_details[0]['dtype'])"],"metadata":{"id":"e2mY92h2DnMt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723061745406,"user_tz":-120,"elapsed":307,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"e57afa4b-786b-497b-8ac8-3dfb84261452"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Shape: [  1 200 200   3]\n","Input Type: <class 'numpy.float32'>\n","Output Shape: [1 1]\n","Output Type: <class 'numpy.float32'>\n"]}]},{"cell_type":"markdown","source":["## Resize Tensors\n","89 Test images --> Input Tensor soll 89 Bilder gleichzeitig bekommen."],"metadata":{"id":"pLf53yAAApuq"}},{"cell_type":"code","source":["interpreter.resize_tensor_input(input_details[0]['index'], (89, 200, 200, 3))\n","interpreter.resize_tensor_input(output_details[0]['index'], (89, 1))\n","interpreter.allocate_tensors()\n","\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","print(\"Input Shape:\", input_details[0]['shape'])\n","print(\"Input Type:\", input_details[0]['dtype'])\n","print(\"Output Shape:\", output_details[0]['shape'])\n","print(\"Output Type:\", output_details[0]['dtype'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWTN4_6aAoZS","executionInfo":{"status":"ok","timestamp":1723055970395,"user_tz":-120,"elapsed":306,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"48265143-ec80-4436-9ac6-62586b2dc92a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Shape: [ 89 200 200   3]\n","Input Type: <class 'numpy.float32'>\n","Output Shape: [89  1]\n","Output Type: <class 'numpy.float32'>\n"]}]},{"cell_type":"markdown","source":["## Datenvorbereitung"],"metadata":{"id":"TGOiZoZHDrs2"}},{"cell_type":"code","source":["x_batch, y_batch = next(test_generator)\n","y_batch = y_batch.reshape(-1, 1)\n","\n","print(\"Test Images dtype:\", x_batch.dtype, \"Test Images shape:\", x_batch.shape)\n","print(\"Test Labels dtype:\", y_batch.dtype, \"Test Labels shape:\", y_batch.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSVoWR2XD0-2","executionInfo":{"status":"ok","timestamp":1723062254973,"user_tz":-120,"elapsed":731,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"e4e59e1e-3a6b-4a1d-c932-9c162dd1e7ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Images dtype: float32 Test Images shape: (1, 200, 200, 3)\n","Test Labels dtype: float32 Test Labels shape: (1, 1)\n"]}]},{"cell_type":"code","source":["x_batch_uint8 = (x_batch * 255).astype(np.uint8)\n","y_batch_uint8 = y_batch.astype(np.uint8)\n","\n","print(\"Test Images dtype:\", x_batch_uint8.dtype, \"Test Images shape:\", x_batch_uint8.shape)\n","print(\"Test Labels dtype:\", y_batch_uint8.dtype, \"Test Labels shape:\", y_batch_uint8.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGDr8QgIKN82","executionInfo":{"status":"ok","timestamp":1722871815552,"user_tz":-120,"elapsed":335,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"a9c6058c-c1ec-4105-b367-592b887c13dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Images dtype: uint8 Test Images shape: (89, 200, 200, 3)\n","Test Labels dtype: uint8 Test Labels shape: (89,)\n"]}]},{"cell_type":"markdown","source":["## Inferenz"],"metadata":{"id":"GSu1V7NgKggG"}},{"cell_type":"code","source":["interpreter.set_tensor(input_details[0]['index'], x_batch)\n","interpreter.invoke()\n","\n","tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n","print(\"Prediction results shape:\", tflite_model_predictions.shape)\n","prediction_classes = np.argmax(tflite_model_predictions, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyWkgbRfKi7f","executionInfo":{"status":"ok","timestamp":1723056037010,"user_tz":-120,"elapsed":42059,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"b6b9fa19-2e20-498b-b2b6-21af61779145"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction results shape: (89, 1)\n"]}]},{"cell_type":"markdown","source":["## Genauigkeit berechnen"],"metadata":{"id":"WsO9_kyxL1lS"}},{"cell_type":"code","source":["accuracy = np.mean(prediction_classes == y_batch)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUiNBcErL5KM","executionInfo":{"status":"ok","timestamp":1723056042705,"user_tz":-120,"elapsed":293,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"64561baf-e360-4bd3-8504-addeccace6a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 53.93%\n"]}]},{"cell_type":"markdown","source":["Die Genauigkeit des Modells ist durch die Konvertierung in Tensorflow Lite deutlich abgefallen und somit ist das Modell so nicht nutzbar.\n","\n","Es wurde sich dazu entschieden das ursprüngliche Modell auf einem RaspberryPi zu verwenden ohne es zu konvertieren."],"metadata":{"id":"iCNYdAILXOlE"}},{"cell_type":"markdown","source":["## Inferenz durchführen"],"metadata":{"id":"zAju8X5JEu6I"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","class TFLiteModel:\n","    def __init__(self, model_path: str):\n","        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n","        self.interpreter.allocate_tensors()\n","\n","        self.input_details = self.interpreter.get_input_details()\n","        self.output_details = self.interpreter.get_output_details()\n","        self.input_scale, self.input_zero_point = self.input_details[0]['quantization']\n","        self.output_scale, self.output_zero_point = self.output_details[0]['quantization']\n","\n","    def predict(self, *data_args):\n","        assert len(data_args) == len(self.input_details)\n","        for data, details in zip(data_args, self.input_details):\n","            self.interpreter.set_tensor(details[\"index\"], data)\n","        self.interpreter.invoke()\n","        output_data = self.interpreter.get_tensor(self.output_details[0][\"index\"])\n","        return output_data\n","\n","    def predict_single_image(self, generator):\n","        # Nimm nur das erste Batch aus dem Generator\n","        data, labels = next(generator)\n","\n","        # Nimm nur das erste Bild und Label aus dem Batch\n","        single_data = np.expand_dims(data[0], axis=0).astype(np.uint8)\n","        true_label = labels[0]\n","\n","        # Vorhersage\n","        pred = self.predict(single_data)[0]\n","        decoded_pred = self.output_scale * (pred - self.output_zero_point)\n","\n","        # Print das wahre Label und die Vorhersage\n","        print(\"True Label:\", true_label)\n","        print(\"Model Prediction (Raw):\", decoded_pred)\n","        predicted_label = (decoded_pred > 0.5).astype(int).flatten()[0]\n","        print(\"Predicted Label:\", predicted_label)\n","\n","        return predicted_label, true_label\n","\n","# Lade das TFLite-Modell\n","model = TFLiteModel(\"/content/drive/MyDrive/Colab Notebooks/models/liteModel.tflite\")\n","\n","# Vorhersage für ein einzelnes Bild\n","predicted_label, true_label = model.predict_single_image(test_generator)\n","\n","# Berechne die Genauigkeit (für nur ein Bild)\n","accuracy = (predicted_label == true_label).astype(int)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNUoAWcnEyfY","executionInfo":{"status":"ok","timestamp":1722793450579,"user_tz":-120,"elapsed":2024,"user":{"displayName":"Maximilian Resch","userId":"11578835195957558610"}},"outputId":"6984a380-fc16-4339-ea52-434df41ddbfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True Label: 1.0\n","Model Prediction (Raw): [0.98046875]\n","Predicted Label: 1\n","Accuracy: 1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GTJpI23Sbsh-"},"execution_count":null,"outputs":[]}]}